{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Cluster A: Dense SCC with 20 nodes\n",
    "cluster_a_nodes = range(1, 21)\n",
    "G.add_nodes_from(cluster_a_nodes)\n",
    "\n",
    "# Add edges to make Cluster A strongly connected\n",
    "for node in cluster_a_nodes:\n",
    "    for target in cluster_a_nodes:\n",
    "        if node != target:\n",
    "            G.add_edge(node, target)\n",
    "\n",
    "# Cluster B: Sparse component with 5 nodes\n",
    "cluster_b_nodes = range(21, 26)\n",
    "G.add_nodes_from(cluster_b_nodes)\n",
    "\n",
    "# Add sparse edges within Cluster B (forming a ring)\n",
    "for i in range(len(cluster_b_nodes)):\n",
    "    G.add_edge(cluster_b_nodes[i], cluster_b_nodes[(i + 1) % len(cluster_b_nodes)])\n",
    "\n",
    "# Bridging edges from Cluster B to Cluster A\n",
    "for node in cluster_b_nodes:\n",
    "    target = random.choice(list(cluster_a_nodes))\n",
    "    G.add_edge(node, target)\n",
    "\n",
    "# **New:** Bridging edges from Cluster A to Cluster B\n",
    "for node in cluster_a_nodes:\n",
    "    if random.random() < 0.1:  # 10% chance to add an edge to Cluster B\n",
    "        target = random.choice(list(cluster_b_nodes))\n",
    "        G.add_edge(node, target)\n",
    "\n",
    "# Visualize the updated graph structure\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=cluster_a_nodes, node_color='blue', label='Cluster A')\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=cluster_b_nodes, node_color='green', label='Cluster B')\n",
    "nx.draw_networkx_edges(G, pos, arrows=True, arrowstyle='->', arrowsize=10, alpha=0.5)\n",
    "plt.title('Updated Graph Structure with Bidirectional Bridging')\n",
    "plt.legend()\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a graph with characteristics where Lazy PageRank converges faster\n",
    "# # 1. Include dangling nodes\n",
    "# # 2. Disconnected components\n",
    "# # 3. Strongly connected clusters\n",
    "\n",
    "# # Initialize the graph\n",
    "# G = nx.DiGraph()\n",
    "\n",
    "# # Add a strongly connected cluster (component 1)\n",
    "# G.add_edges_from([\n",
    "#     (1, 2), (2, 3), (3, 4), (4, 1), (2, 4), (3, 1)\n",
    "# ])\n",
    "\n",
    "# # Add another strongly connected cluster (component 2)\n",
    "# G.add_edges_from([\n",
    "#     (5, 6), (6, 7), (7, 8), (8, 5), (6, 8), (7, 5)\n",
    "# ])\n",
    "\n",
    "# # Add dangling nodes connected to cluster 1\n",
    "# G.add_edges_from([\n",
    "#     (9, 1), (10, 2)\n",
    "# ])\n",
    "\n",
    "# # Add dangling nodes connected to cluster 2\n",
    "# G.add_edges_from([\n",
    "#     (11, 5), (12, 6)\n",
    "# ])\n",
    "\n",
    "# # Add disconnected nodes (dangling nodes with no outgoing edges)\n",
    "# G.add_nodes_from([13, 14])\n",
    "\n",
    "# # Visualize the graph\n",
    "# pos = nx.spring_layout(G, seed=42)  # Position for consistent layout\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# nx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=1500, font_size=15)\n",
    "# plt.title(\"Graph with Properties Favorable for Lazy PageRank\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_iteration(P, alpha=0.85, max_iter=100, tol=1e-6):\n",
    "    n = P.shape[0]\n",
    "    r = np.ones(n) / n  # Initial rank vector\n",
    "    residuals = []\n",
    "    for i in range(max_iter):\n",
    "        r_new = alpha * P.T @ r + (1 - alpha) / n\n",
    "        residual = np.linalg.norm(r_new - r, 1)\n",
    "        residuals.append(residual)\n",
    "        if residual < tol:\n",
    "            break\n",
    "        r = r_new\n",
    "    return r, residuals\n",
    "\n",
    "def power_iteration_lazy(P, alpha=0.85, lazy_prob=0.5, max_iter=100, tol=1e-6):\n",
    "    n = P.shape[0]\n",
    "    r = np.ones(n) / n  # Initial rank vector\n",
    "    residuals = []\n",
    "    P_lazy = lazy_prob * np.eye(n) + (1 - lazy_prob) * P\n",
    "    for i in range(max_iter):\n",
    "        r_new = alpha * P_lazy.T @ r + (1 - alpha) / n\n",
    "        residual = np.linalg.norm(r_new - r, 1)\n",
    "        residuals.append(residual)\n",
    "        if residual < tol:\n",
    "            break\n",
    "        r = r_new\n",
    "    return r, residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the adjacency matrix as a dense numpy array\n",
    "A = nx.adjacency_matrix(G).astype(float).toarray()\n",
    "n = A.shape[0]\n",
    "\n",
    "# Compute row sums\n",
    "row_sums = A.sum(axis=1)\n",
    "dangling_nodes = (row_sums == 0)\n",
    "\n",
    "# Avoid division by zero; replace zeros in row_sums\n",
    "row_sums_fixed = row_sums.copy()\n",
    "row_sums_fixed[dangling_nodes] = 1.0\n",
    "\n",
    "# Normalize to create transition matrix P\n",
    "P = A / row_sums_fixed[:, np.newaxis]\n",
    "\n",
    "# For dangling nodes, set rows to uniform probability\n",
    "P[dangling_nodes, :] = 1.0 / n\n",
    "\n",
    "# Ordinary PageRank\n",
    "pr_ordinary, residuals_ordinary = power_iteration(P)\n",
    "\n",
    "# Lazy PageRank\n",
    "pr_lazy, residuals_lazy = power_iteration_lazy(P, lazy_prob=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(residuals_ordinary, label='Ordinary PageRank')\n",
    "plt.plot(residuals_lazy, label='Lazy PageRank')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Residual Error (L1 Norm)')\n",
    "plt.title('Convergence Rate Comparison')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinary Transition Matrix\n",
    "eigvals_ordinary = np.linalg.eigvals(P.T)\n",
    "\n",
    "# Lazy Transition Matrix\n",
    "P_lazy = 0.5 * np.eye(n) + 0.5 * P\n",
    "eigvals_lazy = np.linalg.eigvals(P_lazy.T)\n",
    "\n",
    "# Sort eigenvalues in descending order\n",
    "eigvals_ordinary = np.sort(np.abs(eigvals_ordinary))[::-1]\n",
    "eigvals_lazy = np.sort(np.abs(eigvals_lazy))[::-1]\n",
    "\n",
    "# Plot the eigenvalues\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(eigvals_ordinary.real, marker='o', label='Ordinary PageRank')\n",
    "plt.plot(eigvals_lazy.real, marker='s', label='Lazy PageRank')\n",
    "plt.xlabel('Eigenvalue Index')\n",
    "plt.ylabel('Eigenvalue Magnitude')\n",
    "plt.title('Spectral Gap Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_hitting_time(G, start_node, target_node, num_simulations=1000, max_steps=1000):\n",
    "    hitting_times = []\n",
    "    for _ in trange(num_simulations, desc=\"Simulating Ordinary Hitting Times\"):\n",
    "        current_node = start_node\n",
    "        steps = 0\n",
    "        while current_node != target_node and steps < max_steps:\n",
    "            steps += 1\n",
    "            neighbors = list(G.successors(current_node))\n",
    "            if not neighbors:\n",
    "                break  # Dead end\n",
    "            current_node = random.choice(neighbors)\n",
    "        if current_node == target_node:\n",
    "            hitting_times.append(steps)\n",
    "        else:\n",
    "            hitting_times.append(max_steps)  # Assign max_steps if target not reached\n",
    "    return np.mean(hitting_times), np.std(hitting_times)\n",
    "\n",
    "def simulate_hitting_time_lazy(G, start_node, target_node, lazy_prob=0.5, num_simulations=1000, max_steps=1000):\n",
    "    hitting_times = []\n",
    "    for _ in trange(num_simulations, desc=\"Simulating Lazy Hitting Times\"):\n",
    "        current_node = start_node\n",
    "        steps = 0\n",
    "        while current_node != target_node and steps < max_steps:\n",
    "            steps += 1\n",
    "            if random.random() < lazy_prob:\n",
    "                continue  # Stay at the same node\n",
    "            neighbors = list(G.successors(current_node))\n",
    "            if not neighbors:\n",
    "                break  # Dead end\n",
    "            current_node = random.choice(neighbors)\n",
    "        if current_node == target_node:\n",
    "            hitting_times.append(steps)\n",
    "        else:\n",
    "            hitting_times.append(max_steps)  # Assign max_steps if target not reached\n",
    "    return np.mean(hitting_times), np.std(hitting_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check mutual reachability\n",
    "def are_mutually_reachable(G, node1, node2):\n",
    "    return nx.has_path(G, node1, node2) and nx.has_path(G, node2, node1)\n",
    "\n",
    "# Select node pairs that are mutually reachable\n",
    "def select_mutually_reachable_pair(G, cluster_a_nodes, cluster_b_nodes):\n",
    "    while True:\n",
    "        node_a = random.choice(list(cluster_a_nodes))\n",
    "        node_b = random.choice(list(cluster_b_nodes))\n",
    "        if are_mutually_reachable(G, node_a, node_b):\n",
    "            return node_a, node_b\n",
    "\n",
    "# Select a valid node pair\n",
    "node_a, node_b = select_mutually_reachable_pair(G, cluster_a_nodes, cluster_b_nodes)\n",
    "print(f\"Selected Node A: {node_a} (Cluster A), Node B: {node_b} (Cluster B)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Hitting and Commute Times\n",
    "\n",
    "# Ordinary Random Walk\n",
    "hitting_time_ab_ord, std_ab_ord = simulate_hitting_time(G, node_a, node_b)\n",
    "hitting_time_ba_ord, std_ba_ord = simulate_hitting_time(G, node_b, node_a)\n",
    "commute_time_ord = hitting_time_ab_ord + hitting_time_ba_ord\n",
    "\n",
    "# Lazy Random Walk\n",
    "hitting_time_ab_lazy, std_ab_lazy = simulate_hitting_time_lazy(G, node_a, node_b, lazy_prob=0.5)\n",
    "hitting_time_ba_lazy, std_ba_lazy = simulate_hitting_time_lazy(G, node_b, node_a, lazy_prob=0.5)\n",
    "commute_time_lazy = hitting_time_ab_lazy + hitting_time_ba_lazy\n",
    "\n",
    "# Prepare Data for Plotting\n",
    "labels = ['Hitting Time A→B', 'Hitting Time B→A', 'Commute Time']\n",
    "ordinary_times = [hitting_time_ab_ord, hitting_time_ba_ord, commute_time_ord]\n",
    "lazy_times = [hitting_time_ab_lazy, hitting_time_ba_lazy, commute_time_lazy]\n",
    "ordinary_std = [std_ab_ord, std_ba_ord, 0]  # Assuming std for commute_time_ord is negligible\n",
    "lazy_std = [std_ab_lazy, std_ba_lazy, 0]    # Assuming std for commute_time_lazy is negligible\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "# Plotting the Results\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.bar(x - width/2, ordinary_times, width, yerr=ordinary_std, capsize=5, label='Ordinary Random Walk', alpha=0.7)\n",
    "plt.bar(x + width/2, lazy_times, width, yerr=lazy_std, capsize=5, label='Lazy Random Walk', alpha=0.7)\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Time (Steps)')\n",
    "plt.title('Hitting and Commute Times Comparison')\n",
    "plt.xticks(x, labels)\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_random_walk(G, start_node, steps=50):\n",
    "    path = [start_node]\n",
    "    current_node = start_node\n",
    "    for _ in range(steps):\n",
    "        neighbors = list(G.successors(current_node))\n",
    "        if not neighbors:\n",
    "            break\n",
    "        current_node = random.choice(neighbors)\n",
    "        path.append(current_node)\n",
    "    return path\n",
    "\n",
    "def simulate_random_walk_lazy(G, start_node, lazy_prob=0.5, steps=50):\n",
    "    path = [start_node]\n",
    "    current_node = start_node\n",
    "    for _ in range(steps):\n",
    "        if random.random() < lazy_prob:\n",
    "            path.append(current_node)  # Stay at the same node\n",
    "            continue\n",
    "        neighbors = list(G.successors(current_node))\n",
    "        if not neighbors:\n",
    "            break\n",
    "        current_node = random.choice(neighbors)\n",
    "        path.append(current_node)\n",
    "    return path\n",
    "\n",
    "# Select a start node from Cluster B\n",
    "start_node = random.choice(list(cluster_b_nodes))\n",
    "print(f\"Simulating walks starting from Node {start_node} (Cluster B)\")\n",
    "\n",
    "# Simulate Ordinary Random Walk\n",
    "path_ord = simulate_random_walk(G, start_node)\n",
    "\n",
    "# Simulate Lazy Random Walk\n",
    "path_lazy = simulate_random_walk_lazy(G, start_node, lazy_prob=0.5)\n",
    "\n",
    "# Function to highlight paths on the graph\n",
    "def plot_walk_path(G, path, title):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=cluster_a_nodes, node_color='blue', alpha=0.5, label='Cluster A')\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=cluster_b_nodes, node_color='green', alpha=0.5, label='Cluster B')\n",
    "    nx.draw_networkx_edges(G, pos, arrows=True, arrowstyle='->', arrowsize=10, alpha=0.3)\n",
    "    # Highlight the path\n",
    "    path_edges = list(zip(path[:-1], path[1:]))\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=path_edges, edge_color='red', width=2, arrows=True)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plotting the paths\n",
    "plot_walk_path(G, path_ord, 'Ordinary Random Walk Path')\n",
    "plot_walk_path(G, path_lazy, 'Lazy Random Walk Path')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Did Ordinary PageRank Converge Faster in Graph 1?\n",
    "\n",
    "- **Graph Structure**: The graph had strong connectivity within Cluster A and sparse connectivity in Cluster B, with bidirectional bridging edges.\n",
    "\n",
    "- **Impact on Random Walks**: In such a graph, the ordinary random walk moves quickly due to high connectivity, especially within Cluster A.\n",
    "\n",
    "- **Lazy Random Walk Effect**: Introducing laziness (probability of staying at the same node) can slow down the convergence in graphs that are already well-connected because it reduces the movement across nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Did Lazy PageRank Converge Faster in Graph 2?\n",
    "\n",
    "- **Dangling Nodes (9, 10, 11, 12, 13, 14):** Lazy PageRank mitigates the need to redistribute ranks uniformly across the graph, reducing global computation.\n",
    "\n",
    "- **Disconnected Components ({1, 2, 3, 4} and {5, 6, 7, 8}):** Lazy PageRank keeps rank localized longer within components, accelerating local convergence.\n",
    "\n",
    "- **Strong Local Clusters:** Nodes within clusters (e.g., {1, 2, 3, 4}) strongly reinforce ranks among themselves, stabilizing faster in Lazy PageRank due to reduced inter-cluster rank dispersion.\n",
    "\n",
    "- **Reduced Teleportation Effect:** Lazy PageRank limits excessive jumping to unrelated nodes, allowing ranks to stabilize more efficiently in dense substructures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a simple random walk on a graph, the transition probability from node $ i $ to node $ j $ is given by the transition matrix $ P $, where $ P_{ij} = \\frac{1}{\\text{deg}(i)} $ if there is an edge between $ i $ and $ j $, and 0 otherwise. This means that at each time step $ t $, the probability distribution $ \\pi_t $ evolves according to:\n",
    "\n",
    "$\n",
    "\\pi_{t+1} = \\pi_t P.\n",
    "$\n",
    "\n",
    "In a lazy random walk, the walker has a probability $ \\alpha $ of staying at the current node and a probability $ (1 - \\alpha) $ of moving to a neighboring node. The transition matrix $ P_{\\text{lazy}} $ for the lazy random walk is therefore:\n",
    "\n",
    "$\n",
    "P_{\\text{lazy}} = \\alpha I + (1 - \\alpha) P,\n",
    "$\n",
    "\n",
    "where $ I $ is the identity matrix. This modification introduces self-loops at each node with probability $ \\alpha $.\n",
    "\n",
    "At time $ t+1 $, the probability distribution $ \\pi_{t+1} $ in the lazy random walk evolves as:\n",
    "\n",
    "$\n",
    "\\pi_{t+1} = \\pi_t P_{\\text{lazy}} = \\alpha \\pi_t I + (1 - \\alpha) \\pi_t P = \\alpha \\pi_t + (1 - \\alpha) \\pi_t P.\n",
    "$\n",
    "\n",
    "**Observation:** The key difference between the lazy random walk and the simple random walk is the inclusion of the term $ \\alpha \\pi_t $, representing the probability of the walker staying at the current node. This self-loop slows down the convergence of the walk compared to the simple random walk because the probability distribution changes more gradually over time.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Given the PageRank transition matrix:\n",
    "\n",
    "$\n",
    "P_g = (1 - p) P + p B,\n",
    "$\n",
    "\n",
    "where $ P $ is a stochastic matrix, $ B = \\frac{1}{n} \\mathbf{1}_{n \\times n} $ is a matrix where each entry is $ \\frac{1}{n} $, and $ p $ is the damping factor (typically $ p = 0.15 $).\n",
    "\n",
    "To prove that $ P_g $ remains stochastic, we need to show two things:\n",
    "\n",
    "1. **Non-negativity:** All entries of $ P_g $ are non-negative.\n",
    "2. **Row sums equal to 1:** The sum of each row in $ P_g $ is 1.\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "1. **Non-negativity:**\n",
    "   - Since $ P $ is stochastic, $ P_{ij} \\geq 0 $ for all $ i, j $.\n",
    "   - Since $ B_{ij} = \\frac{1}{n} \\geq 0 $ for all $ i, j $.\n",
    "   - The coefficients $ (1 - p) $ and $ p $ are non-negative (since $ p \\in [0,1] $).\n",
    "   - Therefore, $ P_g $ entries are non-negative:\n",
    "     $\n",
    "     P_g[i][j] = (1 - p) P[i][j] + p B[i][j] \\geq 0.\n",
    "     $\n",
    "\n",
    "2. **Row sums equal to 1:**\n",
    "   - For each row $ i $:\n",
    "     $\n",
    "     \\sum_{j} P_g[i][j] = (1 - p) \\sum_{j} P[i][j] + p \\sum_{j} B[i][j].\n",
    "     $\n",
    "   - Since $ P $ is stochastic:\n",
    "     $\n",
    "     \\sum_{j} P[i][j] = 1.\n",
    "     $\n",
    "   - Since $ B[i][j] = \\frac{1}{n} $:\n",
    "     $\n",
    "     \\sum_{j} B[i][j] = n \\times \\frac{1}{n} = 1.\n",
    "     $\n",
    "   - Therefore:\n",
    "     $\n",
    "     \\sum_{j} P_g[i][j] = (1 - p)(1) + p(1) = 1.\n",
    "     $\n",
    "\n",
    "**Conclusion:** Since $ P_g $ has non-negative entries and each row sums to 1, $ P_g $ remains a stochastic matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
